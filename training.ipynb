{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azorios/DL1/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from datasets import load_dataset, concatenate_datasets, Dataset\n",
        "from transformers import ResNetForImageClassification\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device, ' will be used.')\n",
        "\n",
        "# transform input\n",
        "# data_transforms = {\n",
        "#     'train': transforms.Compose([\n",
        "#         transforms.RandomResizedCrop(224),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "#     ]),\n",
        "#     'val': transforms.Compose([\n",
        "#         transforms.Resize(256),\n",
        "#         transforms.CenterCrop(224),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "#     ]),\n",
        "#     'test': transforms.Compose([\n",
        "#         transforms.Resize(224),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "#     ])\n",
        "# }\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# datasets\n",
        "fake = load_dataset('poloclub/diffusiondb', '2m_random_10k', split='train', data_dir='./')\n",
        "real = load_dataset('frgfm/imagenette', '320px', split='train+validation', data_dir='./')\n",
        "\n",
        "fake = fake.remove_columns(['prompt', 'seed', 'step', 'cfg', 'sampler', 'width', 'height', 'user_name', 'timestamp', 'image_nsfw', 'prompt_nsfw'])\n",
        "real = real.remove_columns('label')\n",
        "\n",
        "# add label column\n",
        "fake = fake.map(lambda x: {'image': x['image'], 'label':1})\n",
        "real = real.map(lambda x: {'image': x['image'], 'label':0})\n",
        "\n",
        "print(fake)\n",
        "print(real)\n",
        "\n",
        "# split fake dataset into train, validation and test sets\n",
        "fake_train_testvalid = fake.train_test_split(test_size=0.2)\n",
        "fake_test_valid = fake_train_testvalid['test'].train_test_split(test_size=0.5)\n",
        "\n",
        "# split real dataset into train, validation and test sets\n",
        "real_train_testvalid = real.train_test_split(test_size=0.2)\n",
        "real_test_valid= real_train_testvalid['test'].train_test_split(test_size=0.5)\n",
        "\n",
        "# combine fake and real datasets into single dataset for each split\n",
        "train_dataset = concatenate_datasets([fake_train_testvalid['train'], real_train_testvalid['train']]).shuffle(seed=42)\n",
        "val_dataset = concatenate_datasets([fake_test_valid['train'], real_test_valid['train']]).shuffle(seed=42)\n",
        "test_dataset = concatenate_datasets([fake_test_valid['test'], real_test_valid['test']]).shuffle(seed=42)\n",
        "\n",
        "print(train_dataset)\n",
        "print(val_dataset)\n",
        "print(test_dataset)\n",
        "\n",
        "#image transforms fehlen noch => normalizen, siehe oben transforms (huggingface) wichtig!\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "# freeze all parameters\n",
        "for params in model.parameters(): params.requires_grad_ = False\n",
        "nr_filters = model.fc.in_features  # number of input features of last layer\n",
        "model.fc = nn.Linear(nr_filters, 1)"
      ],
      "metadata": {
        "id": "vx7mnBfljT0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}