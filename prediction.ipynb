{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install necessary dependencies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install scikit-learn datasets\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cu117 # for cuda"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import all needed packages."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from torchvision.transforms import Normalize, Compose, Resize, ToTensor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download dataset, remove unnecessary columns and add label 0 to real images and 1 to generated images.\n",
    "Then split the dataset into a train (80%), validation (10%) and test dataset (10%)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    # datasets\n",
    "    fake = load_dataset('poloclub/diffusiondb', '2m_random_10k', split='train', data_dir='./')\n",
    "    real = load_dataset('frgfm/imagenette', '320px', split='train+validation', data_dir='./')\n",
    "\n",
    "    # remove unnecessary columns\n",
    "    fake = fake.remove_columns(\n",
    "        ['prompt', 'seed', 'step', 'cfg', 'sampler', 'width', 'height', 'user_name', 'timestamp', 'image_nsfw',\n",
    "         'prompt_nsfw'])\n",
    "    real = real.remove_columns('label')\n",
    "\n",
    "    # add label column with 0 for real images and for 1 for generated images\n",
    "    fake = fake.map(lambda x: {'image': x['image'], 'label': 1})\n",
    "    real = real.map(lambda x: {'image': x['image'], 'label': 0})\n",
    "\n",
    "    # split fake dataset into train, validation and test sets\n",
    "    fake_train_testvalid = fake.train_test_split(test_size=0.2)\n",
    "    fake_test_valid = fake_train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "    # split real dataset into train, validation and test sets\n",
    "    real_train_testvalid = real.train_test_split(test_size=0.2)\n",
    "    real_test_valid = real_train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "    # combine fake and real datasets into single dataset for each split\n",
    "    train_dataset = concatenate_datasets([fake_train_testvalid['train'], real_train_testvalid['train']])\n",
    "    val_dataset = concatenate_datasets([fake_test_valid['train'], real_test_valid['train']])\n",
    "    test_dataset = concatenate_datasets([fake_test_valid['test'], real_test_valid['test']])\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform and preprocess test data. Convert the images to pixel_values (tensors)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_transforms = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "def transform_test(batch):\n",
    "    batch['pixel_values'] = [test_transforms(img.convert(\"RGB\")) for img in batch['image']]\n",
    "    del batch['image']\n",
    "    return batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions for prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_label(data, device):\n",
    "    \"\"\"\n",
    "    Get image and label data. Convert label data to the same nn output shape.\n",
    "    \"\"\"\n",
    "    image = data['pixel_values'].to(device)\n",
    "    label = data['label'].unsqueeze(1).float().to(device)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def predict_test(test_loader, model, device):\n",
    "    \"\"\"\n",
    "    Predict all the test dataset and calculate confusion matrix, AUROC and classification report with f1 score, precision and recall.\n",
    "    \"\"\"\n",
    "    predictions, targets = [], []\n",
    "\n",
    "    model.eval()\n",
    "    for data in test_loader:\n",
    "        image, label = get_image_label(data, device)\n",
    "\n",
    "        output = torch.sigmoid(model(image))\n",
    "        preds = torch.round(output)\n",
    "\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        label = label.detach().cpu().numpy()\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            predictions.append(preds[i])\n",
    "            targets.append((label[i]))\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    conf_mat = confusion_matrix(targets, predictions)\n",
    "    class_rep = classification_report(targets, predictions, target_names=('Real', 'Generated'))\n",
    "    auroc = roc_auc_score(targets, predictions)\n",
    "\n",
    "    print(conf_mat)\n",
    "    print(class_rep)\n",
    "    print(auroc)\n",
    "\n",
    "    file = open(f'./model_data/resnet50_metrics.txt', 'w')\n",
    "    file.write(f'ResNet50 Dataset1\\n\\nConfusion Matrix\\n\\n{conf_mat}\\n\\nClassification Report\\n\\n{class_rep}\\n\\n'\n",
    "               f'AUROC: {auroc}')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute Prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# used device for computing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device, 'will be used.')\n",
    "\n",
    "# get the dataset\n",
    "_, _, test_dataset = get_dataset()\n",
    "\n",
    "# apply transforms and preprocessing to dataset\n",
    "test_dataset.set_transform(transform_test)\n",
    "\n",
    "# load data\n",
    "batch_size = 32\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# load best model\n",
    "model = torch.jit.load('./model_data/resnet50.pth')\n",
    "model.eval()\n",
    "\n",
    "predict_test(test_loader, model, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}